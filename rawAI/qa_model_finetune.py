# -*- coding: utf-8 -*-
"""QA_Model_Finetune.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ADcVoPMK_vpPHGg6xoweYUr_bzxC_XVZ
"""

import pandas as pd
import numpy as np
import re
from difflib import SequenceMatcher

df_train = pd.read_csv('train.csv')

"""Preprocessing"""

def clean_text(inputString):
  return re.sub('[-=+#/\?:^@*\"※~ㆍ!』\(\)‘|`…》\t\n\”\“·]', ' ', inputString)

df_train['first_party'] = df_train['first_party'].apply(lambda x : clean_text(x))
df_train['second_party'] = df_train['second_party'].apply(lambda x : clean_text(x))
df_train['facts'] = df_train['facts'].apply(lambda x : clean_text(x))

df_test = pd.read_csv('test.csv')

df_test['first_party'] = df_test['first_party'].apply(lambda x : clean_text(x))
df_test['second_party'] = df_test['second_party'].apply(lambda x : clean_text(x))
df_test['facts'] = df_test['facts'].apply(lambda x : clean_text(x))

"""DataSet"""

!pip install transformers

from transformers import DistilBertForQuestionAnswering
model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')
#distilbert-base-uncased-distilled-squad

from transformers import pipeline
qa_model = pipeline("question-answering", model='distilbert-base-uncased-distilled-squad', device=0)

def make_question(first_party,second_party):
    question = "Who won the trial, " + first_party + " or "+ second_party +"?"
    return question

def analyze_model(first_party,second_party,content):
    question = "Who won the trial, " + first_party + " or "+ second_party +"?"
    return qa_model(question = question, context = content)['answer']

def analyze_full_output_model(first_party,second_party,content):
    question = "Who won the trial, " + first_party + " or "+ second_party +"?"
    return qa_model(question = question, context = content)

def str_similarity(first,second,answer):
    first_result = SequenceMatcher(None, first, answer).ratio()
    second_result = SequenceMatcher(None, second, answer).ratio()

    if(first_result > second_result):
        res = np.ceil(first_result)
    else:
        res = 0
    return res

df_train['answer'] = df_train.apply(lambda x : analyze_model(x.first_party, x.second_party, x.facts), axis = 1)
df_train['questions'] = df_train.apply(lambda x : make_question(x.first_party, x.second_party), axis = 1)

df_test['questions'] = df_test.apply(lambda x : make_question(x.first_party, x.second_party), axis = 1)

df_train['first_sim'] = df_train.apply(lambda x: str_similarity(x.first_party, x.second_party, x.answer), axis=1)

df_train['answers'] = df_train.apply(lambda x : analyze_full_output_model(x.first_party, x.second_party, x.facts), axis = 1)

finetune_train_data = df_train[df_train['first_party_winner'] == df_train['first_sim']].copy()

finetune_train_data

def del_dict_key(dic):
  del dic['score']
  return dic

contexts = finetune_train_data['facts']
answers = finetune_train_data['answers']
answers = answers.apply(lambda x : del_dict_key(x))

test_contexts = list(df_test['facts'].values)
test_questions = list(df_test['questions'].values)

questions = finetune_train_data['questions']

def change_name(mydict):
    mydict['text'] = mydict.pop('answer')
    mydict['answer_start'] = mydict.pop('start')
    mydict['answer_end'] = mydict.pop('end')
    return mydict

answers = answers.apply(lambda x : change_name(x))

answers

train_contexts = list(contexts.values)[:900]
val_contexts = list(contexts.values)[900:]

train_questions = list(questions.values)[:900]
val_questions = list(questions.values)[900:]

train_answers = list(answers.values)[:900]
val_answers = list(answers.values)[900:]

"""Load Pretrained Model"""

#!pip install transformers
from transformers import DistilBertTokenizerFast
# initialize the tokenizer
tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')



# tokenize
train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)
val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)

# tokenize
test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)

tokenizer.decode(train_encodings['input_ids'][0])

tokenizer.decode(test_encodings['input_ids'][0])

def add_token_positions(encodings, answers):
    # initialize lists to contain the token indices of answer start/end
    start_positions = []
    end_positions = []
    for i in range(len(answers)):
        # append start/end token position using char_to_token method
        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))
        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))

        # if start position is None, the answer passage has been truncated
        if start_positions[-1] is None:
            start_positions[-1] = tokenizer.model_max_length
        # end position cannot be found, char_to_token found space, so shift position until found
        shift = 1
        while end_positions[-1] is None:
            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)
            shift += 1
    # update our encodings object with the new token-based start/end positions
    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})

# apply function to our data
add_token_positions(train_encodings, train_answers)
add_token_positions(val_encodings, val_answers)

train_encodings.keys()

test_encodings.keys()

import torch

class SquadDataset(torch.utils.data.Dataset):
    def __init__(self, encodings):
        self.encodings = encodings

    def __getitem__(self, idx):
        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}

    def __len__(self):
        return len(self.encodings.input_ids)

# build datasets for both our training and validation sets
train_dataset = SquadDataset(train_encodings)
val_dataset = SquadDataset(val_encodings)

test_dataset = SquadDataset(test_encodings)

from torch.utils.data import DataLoader
from transformers import AdamW
from tqdm import tqdm

# setup GPU/CPU
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
# move model over to detected device
model.to(device)
# activate training mode of model
model.train()
# initialize adam optimizer with weight decay (reduces chance of overfitting)
optim = AdamW(model.parameters(), lr=5e-5)

# initialize data loader for training data
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)

for epoch in range(5):
    # set model to train mode
    model.train()
    # setup loop (we use tqdm for the progress bar)
    loop = tqdm(train_loader, leave=True)
    for batch in loop:
        # initialize calculated gradients (from prev step)
        optim.zero_grad()
        # pull all the tensor batches required for training
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        start_positions = batch['start_positions'].to(device)
        end_positions = batch['end_positions'].to(device)
        # train model on batch and return outputs (incl. loss)
        outputs = model(input_ids, attention_mask=attention_mask,
                        start_positions=start_positions,
                        end_positions=end_positions)
        # extract loss
        loss = outputs[0]
        # calculate loss for every parameter that needs grad update
        loss.backward()
        # update parameters
        optim.step()
        # print relevant info to progress bar
        loop.set_description(f'Epoch {epoch}')
        loop.set_postfix(loss=loss.item())

val_loss, val_score = validation(model, criterion, val_loader, device)

        print(f'Epoch [{epoch}], Train Loss : [{tr_loss:.5f}] Val Loss : [{val_loss:.5f}] Val Score : [{val_score:.5f}]')



start_pred = torch.argmax(outputs['start_logits'], dim=1)
end_pred = torch.argmax(outputs['end_logits'], dim=1)

#acc = ( (start_pred == start_true).sum() / len(start_pred) ).item()

model

start_preds = []
end_preds = []

model.eval()
# setup loop (we use tqdm for the progress bar)
loop = tqdm(test_loader, leave=True)
for batch in loop:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    # train model on batch and return outputs (incl. loss)
    outputs = model(input_ids, attention_mask=attention_mask)
    start_pred = torch.argmax(outputs['start_logits'], dim=1)
    end_pred = torch.argmax(outputs['end_logits'], dim=1)
    start_preds.extend(start_pred.tolist())
    end_preds.extend(end_pred.tolist())

df_test['start_idx'] = start_preds
df_test['end_idx'] = end_preds

df_test

def read_facts(start_idx, facts):
  return facts[start_idx:start_idx+10]

df_test['answer'] = df_test.apply(lambda x : read_facts(x.start_idx,x.facts), axis =1)

df_test

df_test['first_sim'] = df_test.apply(lambda x: str_similarity(x.first_party, x.second_party, x.answer), axis=1)

df_test

#숫자 제거,
#et al. No. Inc. 제거
#, 제거

submit = pd.read_csv('./sample_submission.csv')

submit['first_party_winner'] = df_test['first_sim']
submit.to_csv('./torch_finetune_submit.csv', index=False)

